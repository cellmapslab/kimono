---
title: "<div class='mytitle'>KiMONo</div>Knowledge Guided Multi-Omic Network Inference"
#author: "<center>[Christoph Ogris](https://github.com/cellmapslab/kimono) </center>"
date: "<center>`r format(Sys.time(), '%d %B %Y')`</center>"
mail: "christoph.ogris@helmholtz-muenchen.de"
linkedin: "christoph-ogris-6a223082"
twitter: "christoph_ogris"
github: "00chris00"
home: "www.helmholtz-muenchen.de/icb/index.html"
logo: "logo.png"
output:
  lazyrmd::lazy_render:
    toc: TRUE
    toc_float:
      collapsed: true
      smooth_scroll: false
    number_sections: FALSE
    css: style.css
    self_contained: false
---


<br><br>

> This is a tutorial for multi-modal graph inference and analysis using the KiMONo framework on fictional data. <br> [Ogris et. al, 2021](https://www.nature.com/articles/s41598-021-85544-4)


<center>![Figure 1](intro.png){width='80%'}</center>
<br><br>

Graph inference from multimodal biological data sets of different measurement techniques has always been a big challenge in life sicience. KiMONo infers a multimodal graph by creating a sparse group lasso regression model for each feature. The method uses prior knowledge to pre-weight features. All trained models are then combined in a graph. Here nodes represent an individual input feature, like blood parameters, genes or proteins, and edges are modeled relations between them..



# Example
***
## Libraries
```{r, warning = FALSE,  message=FALSE}
library(kimono) # framework

#Dependencies
library(igraph) # network structures and statistics
library(data.table) # replacing data frames
library(oem)  # SGL implementation
library(foreach) # Paralellization
library(doSNOW) # multi-core support
library(dplyr)  
library(tidyverse)
  

#Visualization
library(ggplot2)
library(cowplot) 
library(DT)

```

## Mulit-modal data

In this example we look at fictional transcriptomic, proteomic and phenotypic data.

* Rows represent samples
* Columns represent features

```{r, warning = FALSE}
phenotype <- fread("data/phenotype.csv")
head(phenotype)

transcriptome <- fread("data/expression.csv")
head(transcriptome)

proteome <- fread("data/proteome.csv")
head(proteome)
```

### Preprocessing
#### Matched samples
KiMONo relies on the fact that we feed it with matched samples. Meaning each row in each data type must represent the same sample.
```{r, warning = FALSE}
phenotype <- phenotype[match(transcriptome$sample, phenotype$sample),]
proteome <- proteome[match(transcriptome$sample, proteome$sample),]
```

#### Dummy coding
```{r, warning = FALSE}
phenotype$z %>% head
```

Character based variables must be either dummy coded or excluded
```{r, warning = FALSE}
phenotype$z <- phenotype$z %>% as.factor %>% as.numeric
phenotype$z %>% head
```

### Final
```{r, warning = FALSE}
input_data <- list(
  'gene' = transcriptome[,-"sample"],
  'protein' = proteome[,-"sample"],
  'phenotype' = phenotype[,-"sample"]
)

#it is recommended to remove the original data to free some memory
rm(transcriptome,phenotype,proteome)
```

## Prior data
***
KiMONo convert a simple csv based files to a prior network which suits us as an inference blueprint. 

```{r, warning = FALSE}
gene_gene <- fread("data/mapping_expr.csv")
gene_gene %>% head
gene_proteome <- fread("data/mapping_expr_prot.csv")
gene_proteome %>% head

```

> Each row represents a pair of features which is **known** to be related.

KiMONo uses the **igraph package** to efficiently incorporate the prior information.
```{r, warning = FALSE}
prior_network <- create_prior_network(rbind(gene_proteome,gene_gene) ) ## prior network
```

#### Plotting prior network
```{r, warning = FALSE}
vertex <- do.call(rbind,strsplit(V(prior_network)$name,split = '___'))

prior_network %>% plot(edge.curved=0,
                       main = 'Prior Network',
     vertex.color = c("steel blue", "orange")[vertex[,1] %>% as.factor %>% as.numeric],
     vertex.frame.color="white",
     vertex.label = vertex[,2], 
     vertex.label.color='black',
     vertex.label.cex=.7,
     layout=layout_randomly, rescale=F) 
legend(x=-1.5, y=-1.1, c("Genes","Proteins"), pch=21,
       col="#777777", pt.bg=c("steel blue", "orange"), pt.cex=2, cex=.8, bty="n", ncol=1)
```

# KiMONo
***

Inference steps: 

1) Load the prior
2) Check if there arre layers without priors if so the algorithm will add each features to every model
3) Iterate over each data type 
4) Train a Sparse Group Lasso model for each node(target or y) in the prior network and determine the:
    * effects sizes of connected features (predictors)
    * r squared 
    * mse
5) Combine all models

<br><br>

Regression model:
\[\begin{aligned} y \sim X\beta + \epsilon \\		\end{aligned}\]
		
Sparse Group Lasso penalty:
\[  \frac{1}{2n} \Bigg|\Bigg| y - \sum_{l=1}^{m} X^{(l)} \beta^{(l)} \Bigg|\Bigg|_{2}^{2} + ( 1 - \alpha ) \lambda \sum_{l=1}^{m} \sqrt{p_{l}}\big|\big|\beta^{(l)}\big|\big|_2  + \alpha\lambda\big|\big|\beta \big|\big|_1 \]

## Call KiMONo
```{r, warning = FALSE}
network <- kimono(input_data, prior_network ,core = 2, infer_missing_prior = TRUE)
#plot network
to_igraph(network) %>% plot_kimono(title='KiMONo Network (directed)')
to_igraph(network, directed = F) %>% plot_kimono(title='KiMONo Network (undirected)')
```

## Result
<br>
Columns:

  * **target** - vector y in regression model
  * **predictor** - each feature in X used in model y
  * **value** - effect size of predictor on target
  * **r_squared** - model performance
  * **mse** - model error
  * **predictor_layer** - input data the predictor belongs to
  * **target_layer** - input data the target belongs to

<br>
```{r, warning = FALSE}
DT::datatable(head(network), class = 'cell-border stripe')
```


# Network Analysis
***

## Quality

Evaluating the r2 for each model gives us the possibility to compare the performances of our models.

> Note the rsquared is the same for each target.  

```{r, warning = FALSE}
gg_all <- network[predictor == '(Intercept)',] %>%  
            ggplot( aes(y=r_squared))  +
                    geom_boxplot()

gg_grouped <- network[predictor == '(Intercept)',] %>%  
            ggplot( aes(y=r_squared,x=target_layer))  +   
                    geom_boxplot(fill=c("steel blue",'#842F39', "orange"))

plot_grid(gg_all, gg_grouped, rel_widths = c(1, 2))


nnodes <- c(network$target, network$predictor) %>% unique %>% length
nedges <- dim(network)[1]

cat('Number of Nodes: ',nnodes)
cat('Number of Edges: ',nedges)
```


## Filter network 

Often we are only interested in models which perform well and have large effect sizes.
```{r, warning = FALSE}
network <- network %>% 
  filter(value > 0.001 | value < -0.001 ) %>% # filter low effects
  filter(r_squared > 0.001)  %>%  # filter low performing models
  filter(predictor != '(Intercept)') # filter all intercepts (should be close to 0 due to normalization step)
```

New network properties
```{r, warning = FALSE}
nnodes <- c(network$target, network$predictor) %>% unique %>% length
nedges <- dim(network)[1]

cat('Number of Nodes: ',nnodes)
cat('Number of Edges: ',nedges)
```

Generate igraph for easier network analysis
```{r, warning = FALSE}
#generate undirected igraph
ig_network <- to_igraph(network, directed=TRUE) 
ig_network %>% plot_kimono
```

## General
```{r, warning = FALSE}
cat('Density: ', ecount(ig_network)/(vcount(ig_network)*(vcount(ig_network)-1)), '\n' )
cat('Reciprocity: ', reciprocity(ig_network) , '\n' )
cat('Transitivity: ', transitivity(as.undirected(ig_network, mode="collapse")) , '\n' )
```


## Node degree and distribution
```{r, warning = FALSE}
deg <- degree(ig_network, mode="all")
cat('Average node degree: ', mean(deg), '\n' )

hist(deg, breaks=1:vcount(ig_network)-1, main="Histogram of node degree")

deg.dist <- degree_distribution(ig_network, cumulative=T, mode="all")

plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, col="orange", 
      xlab="Degree", ylab="Cumulative Frequency")
```

## Hubs and authorities

Hubs were expected to contain catalogs with a large number of outgoing links....

```{r, warning = FALSE}

hs <- hub_score(ig_network, weights=NA)$vector
l <- layout_with_kk(ig_network)


plot(ig_network,
     edge.curved=0,
     vertex.color = c("steel blue",'#842F39', "orange")[vertex[,1] %>% as.factor %>% as.numeric],
     vertex.frame.color="white",
     vertex.label = vertex[,2], 
     vertex.label.color='black',
     vertex.label.cex=.7,
     layout=l, 
     vertex.size=hs*20, main="Hubs"
     ) 

 legend(x=-1.5, y=-1.1, c("Genes","Phenotype","Proteins"), pch=21,
     col="#777777", pt.bg=c("steel blue","#842F39", "orange"), pt.cex=2, cex=.8, bty="n", ncol=1)
 
```

...while authorities would get many incoming links from hubs

```{r, warning = FALSE}
as <- authority_score(ig_network, weights=NA)$vector
plot(ig_network,
     edge.curved=0,
     vertex.color = c("steel blue",'#842F39', "orange")[vertex[,1] %>% as.factor %>% as.numeric],
     vertex.frame.color="white",
     vertex.label = vertex[,2], 
     vertex.label.color='black',
     vertex.label.cex=.7,
     layout=l, 
     vertex.size=as*20, main="Authorities"
     ) 

 legend(x=-1.5, y=-1.1, c("Genes","Phenotype","Proteins"), pch=21,
     col="#777777", pt.bg=c("steel blue","#842F39", "orange"), pt.cex=2, cex=.8, bty="n", ncol=1)
 


```

# Handling missing data

KiMONo has integreated five additional lasso approaches to handle missingness in two different ways:

1. Two-steps approach based on prior imputation and late aggregation
2. Direct missing data handle using inverse covariance approaches

The next snipped code takes the input data used previously for KiMONo example and randomly removes the 5% of the data in the gene and protein matrices alike.

```{r, warning=FALSE,message=FALSE}
set.seed(1234)

missingness <- 0.05

for(layer in c('gene','protein')){
  dat <- as.matrix(input_data[[layer]])
  n <- round(length(dat) * missingness)
  positions_sample <- sample(x = length(dat), size = n)
  dat[positions_sample] <- NA
  input_data[[layer]] <- setDT(as.data.frame(dat))
}
```

## kNN imputation

One of the imputation methods is based on k nearest neighbours averaging.

```{r, warning=FALSE,message=FALSE}
knn_imputed_data <- knn_imputation(input_data,seed = 1234)
```

### knnKiMONo

KiMONo has been boosted to apply sparse group lasso over kNN imputed data (knnKiMONo)

```{r,warning=FALSE,results='hide'}
knn_network <- kimono(knn_imputed_data, prior_network,core = 2, infer_missing_prior = TRUE)
```

```{r, warning=FALSE}
to_igraph(knn_network) %>% plot_kimono(title='knnKiMONo Network (directed)')
to_igraph(knn_network, directed = F) %>% plot_kimono(title='knnKiMONo Network (undirected)')
DT::datatable(head(knn_network), class = 'cell-border stripe')
```

## Multiple imputation

Another two-step approach is based on multiple imputation. KiMONo is powered by *mice* R package and the prior network combined with Pearson correlation (ngMice) to improve the time perfomance. You can find more details about this method in [Henao et. al, 2022](https://www.biorxiv.org/content/10.1101/2022.04.14.488153v1.full.pdf)

```{r,warning=FALSE,results='hide'}
ng_imputed_data <- ngMice(input_data = input_data,prior_network = prior_network,m = 5)
```

### GALasso

Group Adaptive Lasso (GALasso), applies an adaptive weight for small regression coefficients and applies a group penalty as uniform variable selection across imputed datasates ( [Du et. al, 2020](https://arxiv.org/pdf/2003.07398.pdf) ).

```{r, warnings=FALSE,results='hide',message=FALSE}
galasso_network <- kimono(input_data, prior_network, ng_imputed_data, method = 'galasso', ADW_calculation = TRUE, core = 2, infer_missing_prior = TRUE)
```

```{r,warning=FALSE}
to_igraph(galasso_network) %>% plot_kimono(title='GALasso Network (directed)')
to_igraph(galasso_network, directed = F) %>% plot_kimono(title='GALasso Network (undirected)')
DT::datatable(head(galasso_network), class = 'cell-border stripe')
```

### SALasso

Stack Adaptive Lasso (SALasso), it is the summation of the objective functions across imputed datasets and optimize them jointly. As equal as GALasso, adaptive weights can be calculated to penalize the smaller regression coefficients ( [Du et. al, 2020](https://arxiv.org/pdf/2003.07398.pdf) ).

```{r, warnings=FALSE,results='hide',message=FALSE}
salasso_network <- kimono(input_data, prior_network, ng_imputed_data, method = 'salasso', ADW_calculation = TRUE, core = 2, infer_missing_prior = TRUE)
```

```{r,warning=FALSE}
to_igraph(salasso_network) %>% plot_kimono(title='SALasso Network (directed)')
to_igraph(salasso_network, directed = F) %>% plot_kimono(title='SALasso Network (undirected)')
DT::datatable(head(salasso_network), class = 'cell-border stripe')
```

## Inverse covariance estimation


### CoCoLasso

Convex Contained Lasso (CoCoLasso) allows the calculation of coefficients through the sample covariant matrix of X and the sample vector of X and *y* calculation. Furthermore, to avoid problems related to negative eigenvector and no-convexing optimization solutions, this method used an alternating direction methods of multipliers algorithm ( [Takada et. al, 2019](https://arxiv.org/pdf/1811.00255.pdf) ).

```{r,results='hide'}
coco_network <- kimono(input_data, prior_network, method = 'lasso_coco', core = 2, infer_missing_prior = TRUE)
```

```{r,warning=FALSE}
to_igraph(coco_network) %>% plot_kimono(title='CoCoLasso Network (directed)')
to_igraph(coco_network, directed = F) %>% plot_kimono(title='CoCoLasso Network (undirected)')
DT::datatable(head(coco_network), class = 'cell-border stripe')
```

### HMLasso

Lasso with High Missing rate (HMLasso) is a method proposed as a weighted version of CoCoLasso to avoid the problem of no positive semifinite (PSD) matrix aggregating a covariant matrix calculated from mean imputation matrix. The combination of both allows a low-biased but PSD covariant matrix. To improve the Lasso model optimization, a weighted Frobenius norm is added with alpha higher or equal to zero ( [Takada et. al, 2019](https://arxiv.org/pdf/1811.00255.pdf) ).

```{r,results='hide'}
hm_network <- kimono(input_data, prior_network, method = 'lasso_hm', core = 2, infer_missing_prior = TRUE)
```

```{r,warning=FALSE}
to_igraph(hm_network) %>% plot_kimono(title='HMLasso Network (directed)')
to_igraph(hm_network, directed = F) %>% plot_kimono(title='HMLasso Network (undirected)')
DT::datatable(head(hm_network), class = 'cell-border stripe')
```

### BDCoCoLasso

Block-Descent CoCoLasso (BDCoCoLasso) is another alternative for CoCoLasso adding block-coordinate descent to deal with the partial corrupted covariant matrices across the convex optimization ( [Escribe et. al, 2021](https://onlinelibrary.wiley.com/doi/epdf/10.1002/gepi.22430) ).

```{r,results='hide'}
bdcoco_network <- kimono(input_data, prior_network, method = 'lasso_BDcoco', core = 2, infer_missing_prior = TRUE)
```

```{r,warning=FALSE}
to_igraph(bdcoco_network) %>% plot_kimono(title='BDCoCoLasso Network (directed)')
DT::datatable(head(bdcoco_network), class = 'cell-border stripe')
```

# Troubleshooting
***
## Installation

You can either install KiMONo locally by cloning the repository or using the devtools package.

### Github Installation

1. Install the devtools package and load it in R

```{r ,eval = FALSE }
install.packages("devtools")
library(devtools)
```

2. Install KiMONo in R and load the package
```{r , eval = FALSE }
install_github("cellmapslab/kimono")
library(kimono)
```

### Local Installation

1. In your terminal change the working directory to the location you want to install KiMONo 

2. Clone the repository: 
```{sh , eval = FALSE }
git clone https://github.com/cellmapslab/kimono.git
```

3. Install KiMONo in R and load the package 

```{r , eval = FALSE }
install.packages("yourpath/kimono/", repos = NULL, type = "source")
library(kimono)
```


## Dependencies CentOS
### oem
 CentOS needs a different version of RcppArmadillo(https://www.gitmemory.com/RcppCore)  
```{r , eval = FALSE }
 install.packages("RcppArmadillo", repos="https://rcppcore.github.io/drat")
```

# Session
***
```{r , eval = FALSE }
 sessionInfo()
```


